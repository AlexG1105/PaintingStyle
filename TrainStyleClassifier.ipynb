{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import ImageFolder\n",
    "import os\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import pretrainedmodels\n",
    "from adamW import AdamW\n",
    "#from lr_finder import LRFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example code for only one of my attribute training sets\n",
    "path = 'Painter/PaintingsDataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "#NOTE: CHANGE THIS IF YOU WANT TO SWITCH DIR\n",
    "#removes images from training set that are corrupt.\n",
    "images_path = 'Painter/PaintingsDataset'\n",
    "image_extensions = ['.jpg', '.png', '.jpeg']\n",
    "images = [os.path.join(dp, f) for dp, dn, filenames in os.walk(images_path)\n",
    "         for f in filenames if os.path.splitext(f)[1].lower() in image_extensions]\n",
    "\n",
    "for i, item in enumerate(images):\n",
    "    try:\n",
    "        im = Image.open(item)\n",
    "        if item.split('.')[-1] == 'png':\n",
    "            rgb_im = im.convert('RGB')\n",
    "            os.remove(item)\n",
    "            print('removed png' + item)\n",
    "            rgb_im.save(item.split('.')[0] + '.jpg')\n",
    "    except IOError:\n",
    "        os.remove(item)\n",
    "        print('removed '+ item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is necessary because all of the images in my training set are symbolic links\n",
    "def loadsymlink(path):\n",
    "    returnImage = Image.open(os.readlink(path))\n",
    "    return returnImage.convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "data_transforms = {\n",
    "    'train':\n",
    "        transforms.Compose([\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize\n",
    "        ]),\n",
    "    'valid':\n",
    "        transforms.Compose([\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.ToTensor(),\n",
    "            normalize\n",
    "        ])\n",
    "}\n",
    "\n",
    "image_datasets = {\n",
    "    'train':\n",
    "        ImageFolder(os.path.join(path,'train'), data_transforms['train']),\n",
    "    'valid':\n",
    "        ImageFolder(os.path.join(path,'valid'), data_transforms['valid'])}\n",
    "\n",
    "dataloaders = {\n",
    "    'train':\n",
    "        torch.utils.data.DataLoader(\n",
    "            image_datasets['train'],\n",
    "            batch_size=8,\n",
    "            shuffle=True,\n",
    "            num_workers=4),\n",
    "    'valid':\n",
    "        torch.utils.data.DataLoader(\n",
    "            image_datasets['valid'],\n",
    "            batch_size=8,\n",
    "            shuffle=False,\n",
    "            num_workers=4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating learning rate scheduler\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = models.resnet34(pretrained=True).to(device)\n",
    "\n",
    "#good LR always happens to be small for AdamW\n",
    "#optimizer = AdamW(model.parameters(), lr=1e-5, weight_decay=1e-5)\n",
    "optimizer = optim.SGD(model.parameters(), lr=5e-3, weight_decay=5e-3)\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(num_ftrs, 8).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"creating learning rate scheduler\")\n",
    "\n",
    "steps = len(dataloaders['train'])\n",
    "exp_lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LRFinder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b95ab4349c34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#typically I get my best lr right before the descent in loss, make sure to set lr = 1e-8 before running\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlr_finder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLRFinder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlr_finder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlr_finder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LRFinder' is not defined"
     ]
    }
   ],
   "source": [
    "#typically I get my best lr right before the descent in loss, make sure to set lr = 1e-8 before running\n",
    "lr_finder = LRFinder(model, optimizer, criterion, device='cuda')\n",
    "lr_finder.range_test(dataloaders['train'], end_lr=1, num_iter=100)\n",
    "lr_finder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, dataloaders, scheduler=None, num_epochs=20,cycle_mult=1):\n",
    "\n",
    "    steps = len(dataloaders['train'])\n",
    "    completed = 0\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    \n",
    "    dataset_sizes = {'train':len(dataloaders['train'].dataset),'valid':len(dataloaders['valid'].dataset)}\n",
    "    \n",
    "    #wandb.watch(model)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    " \n",
    "        epoch_loss = 1.0\n",
    "\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    " \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    " \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    " \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    " \n",
    "                if phase == 'train':\n",
    "                    if scheduler is not None:\n",
    "                        steps -= 1\n",
    "                        scheduler.step()\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    " \n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    " \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "        \n",
    "            if phase == 'valid':\n",
    "                #wandb.log({'epoch_loss':epoch_loss,'epoch_acc':epoch_acc})\n",
    "                \n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model_wts = model.state_dict()\n",
    "        \n",
    "        \n",
    "        if scheduler is not None:\n",
    "            lrval = scheduler.get_lr()[0]\n",
    "            print('steps: %d lr: %.8f'%(steps,lrval))\n",
    "            \n",
    "        if (steps <= 0):\n",
    "            steps = len(dataloaders['train'])\n",
    "            print(steps)\n",
    "            scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, steps)\n",
    "\n",
    "        print('{} loss: {:.4f}, acc: {:.4f}'.format(phase,\n",
    "                                                    epoch_loss,\n",
    "                                                    epoch_acc))    \n",
    "    \n",
    "    torch.save(best_model_wts, 'vipsave.pt')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "----------\n",
      "valid loss: 1.4778, acc: 0.4559\n",
      "Epoch 2/20\n",
      "----------\n",
      "valid loss: 1.3489, acc: 0.4941\n",
      "Epoch 3/20\n",
      "----------\n",
      "valid loss: 1.3954, acc: 0.4765\n",
      "Epoch 4/20\n",
      "----------\n",
      "valid loss: 1.2959, acc: 0.4882\n",
      "Epoch 5/20\n",
      "----------\n",
      "valid loss: 1.3675, acc: 0.4765\n",
      "Epoch 6/20\n",
      "----------\n",
      "valid loss: 1.3464, acc: 0.5412\n",
      "Epoch 7/20\n",
      "----------\n",
      "valid loss: 1.3070, acc: 0.5176\n",
      "Epoch 8/20\n",
      "----------\n",
      "valid loss: 1.4109, acc: 0.4941\n",
      "Epoch 9/20\n",
      "----------\n",
      "valid loss: 1.5158, acc: 0.4912\n",
      "Epoch 10/20\n",
      "----------\n",
      "valid loss: 1.5125, acc: 0.5206\n",
      "Epoch 11/20\n",
      "----------\n",
      "valid loss: 1.4831, acc: 0.5176\n",
      "Epoch 12/20\n",
      "----------\n",
      "valid loss: 1.5267, acc: 0.5324\n",
      "Epoch 13/20\n",
      "----------\n",
      "valid loss: 1.5896, acc: 0.5059\n",
      "Epoch 14/20\n",
      "----------\n",
      "valid loss: 1.6111, acc: 0.4941\n",
      "Epoch 15/20\n",
      "----------\n",
      "valid loss: 1.6979, acc: 0.4765\n",
      "Epoch 16/20\n",
      "----------\n",
      "valid loss: 1.6867, acc: 0.4676\n",
      "Epoch 17/20\n",
      "----------\n",
      "valid loss: 1.5895, acc: 0.5265\n",
      "Epoch 18/20\n",
      "----------\n",
      "valid loss: 1.6957, acc: 0.4882\n",
      "Epoch 19/20\n",
      "----------\n",
      "valid loss: 1.8368, acc: 0.4471\n",
      "Epoch 20/20\n",
      "----------\n",
      "valid loss: 1.7196, acc: 0.4735\n"
     ]
    }
   ],
   "source": [
    "model_trained = train_model(model, criterion, optimizer, dataloaders, scheduler=None, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('vipsave.pt'))\n",
    "torch.save(model_trained, 'PaintingsClassifier.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
